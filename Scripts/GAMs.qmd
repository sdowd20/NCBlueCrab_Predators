---
title: "GAMs"
format: html
editor: visual
---

#### Load packages, functions, and datasets

```{r}
#Load packages and functions 
packages <- c("ggplot2", "tidyverse", "lubridate", "sf", "sp", "dplyr", "rnaturalearth", "readr", "readxl", "spatialEco", "rstatix", "viridis", "BBmisc", "corrplot", "mgcv")

invisible(lapply(packages, library, character.only= TRUE))

standard_theme <- theme_bw() + theme(panel.border = element_rect(fill=NA, colour = "black")) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(legend.text.align= 0, legend.title= element_text(size = 12), legend.text = element_text(size= 10), axis.text=element_text(size=10), axis.title=element_text(size=12))

#Load in datasets
##Standardized catch per unit effort 
CPUE_grid_avg_edt <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.csv")
CPUE_grid_avg_edt <- CPUE_grid_avg_edt[,-1]
CPUE_grid_avg_edt <- CPUE_grid_avg_edt %>% mutate_at(c("Sedsize_common", "ShorelineType", "ITP", "Survey"), as.factor)
CPUE_grid_avg_edt$Speciescommonname <- gsub(" ", "_", CPUE_grid_avg_edt$Speciescommonname)

##Count dataset 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd)) #need to remove or R will get confused 
df_count$Speciescommonname <- gsub(" ", "_", df_count$Speciescommonname)

#Pivot-wider datasets: 
##Standardized catch per unit effort dataset wide 
df_CPUE_wide <- CPUE_grid_avg_edt %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "mean_CPUE_stdzd") %>% drop_na() #this removes three rows where NAs were present, feel comfortable doing this b/c a lot of most species had at least 1 NA (some 2), could be an issue from pulling the data or 

length(unique(df_CPUE_wide$gridID))

df_CPUE_wide %>% group_by(gridID) %>% tally() %>% pull(n) %>% table() #how many instances for gridID, make sure this is consistent data to make sure there is nothing weird w/ 1s 

##Binary dataset (0 or 1):  
df_binary_wide <- df_CPUE_wide %>% mutate_at(vars(15:41), ~ ifelse(. > 0, 1, 0))

##Count dataset wide 
df_count_wide <- df_count %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

#Form train/testing datasets by dividing 80% 20% 
set.seed(777)
##Randomly split data in R
sample_size = floor(0.8*nrow(df_CPUE_wide)) #take 80% of rows, # is same b/w dfs

##CPUE model
picked_CPUE = sample(seq_len(nrow(df_CPUE_wide)),size = sample_size)
df_CPUE_wide_test =df_CPUE_wide[-picked_CPUE,]
df_CPUE_wide_train =df_CPUE_wide[picked_CPUE,]

##Binary model
picked_binary = sample(seq_len(nrow(df_binary_wide)),size = sample_size)
df_binary_wide_test = df_binary_wide[-picked_binary,]
df_binary_wide_train = df_binary_wide[picked_binary,]

##Poisson model
picked = sample(seq_len(nrow(df_count_wide)),size = sample_size) 
df_count_wide_test = df_count_wide[-picked,]
df_count_wide_train = df_count_wide[picked,]

#Load GAM formula
gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=10) + s(avg_ssal, bs="ts", k=10) + s(avg_stemp, bs="ts", k=10) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=10) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + s(gridID, bs= "re") + factor(FishingAll_num) + factor(Sedsize_common) + factor(ShorelineType) #gridID as random effect: diff. variance for a grid, could also do first difference approach (year to year)
```

#### Overview:

GAMs, or generalized additive models, provide more flexibility than linear models to explore ecological data. A GAM is a form of a generalized linear model with a linear predictor involving a sum of smooth functions of covariates. They have three parts: 1) a random part, which describes the variability in data by means of an exponential-family probability distribution 2) a structural part which is a linear model 3) a link function that connects the structural and random part. Transformations here are applied to the predictions of a linear model. The link is different depending on the regression used: identity for linear regression, log for poisson regression (counts), and logit for logistic regression (0 or 1). GAMs assume additivity and when a model is additive, the effect of one covariate on another is independent from the value of another covariate.

The k value is the number of basis functions that determines how wiggly the model is (smoothing parameter of a spline). "The value(s) for k set the upper limit on the wiggliness of the smooth function(s). The penalty measures the wiggliness of the function (it is typically the squared second derivative of the smooth summed over the range of the covariate). The model then estimates values for the coefficients for the basis functions representing each smooth and chooses smoothness parameter(s) by maximizing the penalized log likelihood criterion. The penalized log likelihood is the log likelihood plus some amount of penalty for wiggliness for each smooth" (stack overflow). A spline is a piece wise polynomial functions that are used as a smoothing technique. A rule of thumb is that it should be between 5 and the number of years in the dataset (start with 2\*number of decades in dataset). A low k-index (\< 1) might indicate that k is too low especially if edf is close to k'. Change k from there and see if p-value increases/k-index, compare k and edf values in addition to looking at p value. Small and significant p values indicate that residuals are not randomly distributed as there are not enough basis functions. It is important to know that the number of knots is not always just k. "The value you give to k sets the dimensionality of the basis, which implies a certain number of knots" (stack overflow). In the GAM function, you can specify the number of knots outside of specifying the k. Normally, there is not a need to set the knots yourself.

Smoothers are added to continuous variables in GAMs which is denoted by s() to fit the data. The s operator produces the spline base expansion. Different splines can be added to the model. One example is bs= "ts" which is a thin plate spline that is a smoothing basis for predictor variables (smoothing penalty). Thin plate spine basis are the default in the mgcv package. Thin plate splines tend to have better RMSE performance but are more computationally expensive. If you have a reason to do P-spliens or B-splines you can use those and if not, thin plate splines are fine. GAM in R can only accept spline smoothers (number of knots) and not LOESS. It is important to have a good compromise between roughness and smoothness. The parameter Î» specifies how much weight the roughness penalty will get. It is important to note that regression spilnes don't implement penalization by reducing the number of knots rather they do this by reducing the coefficients of spline terms.

How do we know when to drop a model? If the answers to all three of these quesitons are yes, then drop it:

1)  Are the EDF for the questioned term approaching 1 (i.e., linear effect)?
2)  Is the confidence interval of the term including zero throughout its domain? (i.e., high p-value)
3)  Does the GCV (generalized cross validation) score for the entire model drop when the term is removed?

Helpful articles: -smoothers and k: https://stats.stackexchange.com/questions/243367/smoothing-methods-for-gam-in-mgcv-package -choosing k: https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/choose.k.html -stack overflow: https://stackoverflow.com/questions/60078003/gam-in-r-is-it-a-spline-model-with-automated-knots-selection

#### Diagnostics

```{r}
#Exploratory graphs: left skewed and zero-inflated model
df_CPUE_wide %>% ggplot() + geom_histogram(aes(x= red_drum), bins= 10) + xlab("CPUE") + ylab("Counts") + standard_theme
df_binary_wide %>% ggplot() + geom_histogram(aes(x= red_drum), bins= 10) + xlab("Presence/absence") + ylab("Counts") + standard_theme
df_count_wide %>% ggplot() + geom_histogram(aes(x= red_drum), bins= 10) + xlab("Counts") + ylab("Counts") + standard_theme

prop_0 <- 100*sum(df_CPUE_wide$red_drum == 0)/nrow(df_CPUE_wide) #only 50% 
```

#### Initial models:

Helpful articles: -Model output: https://noamross.github.io/gams-in-r-course/chapter2

```{r}
#Generalized linear model:
glm <- glm(red_drum ~ avg_depth + avg_ssal + avg_stemp + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + spot, data = df_count_wide_train, family="poisson")
summary(glm)
#report(glm)
table(df_count_wide_train$red_drum)
table(df_binary_wide_train$red_drum)
#Look into outliers more 

library(GGally)
df_count_wide_train %>% dplyr::select(bonnethead_shark, atlantic_croaker, southern_flounder, spot, red_drum) %>% ggpairs() 

#report(flounder_glm)
glm_pred <- predict(glm, df_CPUE_wide_test, type = "response") %>% tibble(family = "GLM", pred = .) %>% mutate(red_drum= df_CPUE_wide_test$red_drum)

#Negative binomial: related to poisson, use for count data
binomial_neg <- gam(gam_formula, family= "nb", data= df_count_wide_train)
summary(binomial_neg)
gam.check(binomial_neg)
summary(binomial_neg)
binomial_neg_pred <- predict(binomial_neg, df_binary_wide_test, type = "response") %>% tibble(family = "Negative Binomial", pred = .) %>% mutate(red_drum= df_binary_wide_test$red_drum)

#Poisson model did not work because it is for integers
poisson <- gam(gam_formula, family=poisson(), data= df_count_wide_train)
summary(poisson)
gam.check(poisson)
```

#### Tweedie:

The Tweedie distribution is an example of an exponential dispersion model where there is a common mathematical structure such as a link function. This distribution contains three parameters: the mean, standard deviation, and p which can stand for continuous normal, gamma, Poisson, or inverse Gaussian distributions. While the probability density function can't be evaluated with this distribution, a special algorithm is created for density calculation.

For tw() in the mgcv package, the variance function powers are between 1 (Poisson) and 2 (gamma). This power can be used to specify a distribution or can be estimated in the model. The best smoother parameter estimation method fitting method is either maximum likelihood (ML) or restricted maximum likelihood (REML) as they avoid undersmoothing. With maximum likelihood, parameters are estimated by maximizing the likelihood function. As opposed to ML, REML assumes fixed effects are known and only estimates variance components of random effects. Since ML estimates fixed and random effects simultaneously, biased estimates of variance components of random effects occur (https://aitechtrend.com/choosing-the-right-statistical-method-maximum-likelihood-vs-reml/#google_vignette). The common link function for Tweedie is the log link. Here are some helpful resources on Tweedie distributions in general: https://r.qcbs.ca/workshop08/book-en/other-distributions.html https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/Tweedie.html

```{r}
tweedie <- gam(gam_formula, family= tw(link= "log"), data= df_count_wide_train, method= "REML")
summary(tweedie)

#gam(rsd~s(avg_ssal,k=5,bs="cs"),gamma=1.4,data=df_CPUE_wide_train) ## fine
#gam(rsd~s(avg_depth,k=40,bs="cs"),gamma=1.4,data=df_CPUE_wide_train) ## fine
#gam(rsd~s(avg_sdo,k=10,bs="cs"),gamma=1.4,data=df_CPUE_wide_train) ## `k' too low
#gam(rsd~s(x3,k=40,bs="cs"),gamma=1.4,data=dat) ## fine

tweedie_pred <- predict(tweedie, df_count_wide_test, type = "response") %>% tibble(family = "Tweedie", pred = .) %>% mutate(red_drum= df_count_wide_test$red_drum)

#covariance plot 
plot(tweedie,pages=1,se=T, residuals=T,pch=1)
```

#### Delta models

Delta (hurdle models) are a two part model with one model for zero vs. non-zero data and another model for the positive component. Hurdle models are more appropriate than something like a Tweedie when there are differences in the processes controlling presence vs. abundance, or when greater flexibility to account for dispersion is required. As ecological data often has more zeros than is expected if the process generating their data was only from a standard probability distribution, there are multiple methods for dealing with zero inflation. One of these methods is the hurdle model where the zero and non-zero data are in one model and the non-zero data is in another.

There can be Delta-gamma, Delta-lognormal, Delta-NB1 (negative binomial), and Delta-NB2 model types. With ziplss() in gam(), a zero inflated (hurdle) Poisson location-scale model family is fit to data. One linear predictor in the model controls the probability of presence (binomial) and the other controls the mean given presence with ocunts (poisson). Within a list of formulae, the linear predictors are used. The first formulae is for the linear predictor for the Poisson parameter and the second is for the probability of presence. These hurdle models should only be used when 1) there are a large number of zero counts in the data and 2) the positive counts approximate a Poisson distribution.

Helpful resources: -https://pbs-assess.github.io/sdmTMB/articles/delta-models.html -Modeling relative abundance and combining results: https://cornelllabofornithology.github.io/ebird-best-practices/abundance.html

```{r}
#Run binomial and poisson models separately
delta <- gam(list(gam_formula, ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) + factor(ShorelineType)), family= ziplss(), data= df_count_wide_train, method = "REML")
summary(delta) #binomial: argument excessive 0 

gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) + factor(ShorelineType)

#spatial autocorrelation could be occurring- put average lat and lon near each other, could look at spatially lagged predictors (congtiguity matrix) 

#Combine both models into one 
inv_link <- binomial(link = "cloglog")$linkinv #inverse link function, cloglog is the link 
delta_pred <- predict(delta, df_count_wide_test, type = "link") %>% as.data.frame() %>% transmute(family = "Zero-inflated Poisson", pred = inv_link(V2) * exp(V1)) %>% mutate(red_drum= df_count_wide_test$red_drum) #transmute makes new data frame w/ only specified computations, multiply effects of each submodel, on probability scale 
```

#### Compare models

There is a number of criteria that can be checked when deciding which variables to remove. If a variable has a low EDF (close to 1), then it can be removed. If terms meant to stay in the model are removed, it would cause a further increase of the model GCV.

The removal of any other term would result in a further increase of the model GCV, and it is not justified by the covariate effect (EDF\>\>1 and CI not always including 0)

```{r}
test_pred <- bind_rows(delta_pred, tweedie_pred, binomial_neg_pred, glm_pred) %>% mutate(family = as_factor(family))

#Spearman's Rank Correlation: assess fit of models, how well model estimated ranking of sites from highest to lowest abundance 
test_pred %>% group_by(family) %>% summarise(rank_cor = cor.test(red_drum, pred, method = "spearman", exact = FALSE)$estimate) %>% ungroup()

#See how many observations are underestimated by an order of mangitude or more
test_pred %>% group_by(family) %>% summarize(n = sum(red_drum/ pred > 10),
pct = mean(red_drum / pred > 10))

#Mean absolute deviation: get a sense of quality of magnitude of predicted counts, describes average deviation b/w observation and prediction (variation around mean), average of absolute deviations from a central point, low MAD is good 
test_pred %>% group_by(family) %>% summarise(mad = mean(abs(red_drum - pred), na.rm = TRUE)) %>% ungroup()
```

##### Compare models: 2

```{r}
#Tweedie and negative binomial look the best 
gam.check(delta)
gam.check(tweedie)
gam.check(binomial_neg)
gam.check(glm)

summary(tweedie)
summary(binomial_neg)

#edf: gets at curveture and non-linearity 


#QQplot: along line, no trend in residuals vs. linear predictor, normal dist of residuals, 

#Tweedie as best then neg binomial, delta, then glm, caution: don't think w/ REML method this is a valid comparison of GAM to GLM 
AIC(delta) #AIC: estimate of prediction error, AIC calculated for GAM is a conditional AIC, likelihood is of all model coefficients set to their maximum penalized likelihood estimates
AIC(tweedie)
AIC(binomial_neg)
AIC(glm)

#Significant difference in fit?
lrtest(tweedie, delta) #yes, there is a significant difference in fit 

#Check k
k.check(delta)
summary(delta)
k.check(tweedie)
k.check(binomial_neg)
summary(glm)
summary(tweedie)$sp.criterion

#F test
anova(tweedie,glm,test="F")
```

## Repeated K-fold cross-validation

"The k-fold cross-validation method evaluates the model performance on different subset of the training data and then calculate the average prediction error rate. The algorithm is as follow: Randomly split the data set into k-subsets (or k-fold) (for example 5 subsets) Reserve one subset and train the model on all other subsets Test the model on the reserved subset and record the prediction error Repeat this process until each of the k subsets has served as the test set. Compute the average of the k recorded errors.Lower value of K is more biased and hence undesirable. On the other hand, higher value of K is less biased, but can suffer from large variability. In practice, one typically performs k-fold cross-validation using k = 5 or k = 10, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance. The process of splitting the data into k-folds can be repeated a number of times, this is called repeated k-fold cross validation."

From: Sarah Roberts, Statistics for Environmental Scientists with references from James et al. (2014).

Helpful articles: -James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. An Introduction to Statistical Learning: With Applications in R. Springer Publishing Company, Incorporated. -K-fold cross validation w/ GAMs: https://p8105.com/cross_validation.html -How to build out models for train: http://topepo.github.io/caret/train-models-by-tag.html#Generalized_Additive_Model https://community.rstudio.com/t/how-to-pass-pscl-hurdle-two-part-formula-input-to-caret/46276 https://community.rstudio.com/t/cross-validation-with-zero-inflated-or-hurdle-model/46466

```{r}
library(interactions)
library(car)
library(lmtest)
library(gvlma)
library(rstatix)
library(tidyverse)
library(caret)
library(gtools)

# Define training control
set.seed(123) 
train.control <- trainControl(method = "repeatedcv", number = 3, repeats = 5) #number: of folds or resampling iterations, repeats: number of complete sets of folds to compute, 10 k-fold cross-validation that is repeated 5 times 

#Build out tweedie model 
gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) + factor(ShorelineType)

model <- train(red_drum ~ avg_stemp + avg_sdo + avg_ssal,
  data = df_count_wide,  # Your dataset
  method = "gam",   # Specify the GAM model
  trControl = train.control, # Use the custom control object
  family = tw())  # Specify the Tweedie distribution
```

##looping You can loop through different combinations of predictor variables in k fold cross validation. This is a function I wrote to get out all of the possible combinations of our linear models - be very very careful with this

```{r}
pastePerm<- function(row, names){
  keep<- which(row==1)
  if(length(keep)==0){
    return('1')
  }else{
    return(paste(names[keep],collapse='+'))
  }
}
dredgeform<- function(pred, covars, alwaysIn=''){
  p<- length(covars)
  perm.tab<- permutations(2, p, v=c(0,1), repeats.allowed=T)
  myforms<- NULL
  for(j in 1:nrow(perm.tab)){
    myforms[j]<- pastePerm(perm.tab[j,], covars)
  }
  myforms<- paste0(pred, '~ 1', alwaysIn,'+', myforms)
  return(myforms)
}

allformulas<- dredgeform(pred = "red_drum", covars = c("avg_depth", "avg_ssal", "avg_stemp", "SAVDist_km", "InletDist_km", "NoFishRest", "atlantic_menhaden", "atlantic_croaker", "southern_flounder", "FishingAll_num", "Sedsize_common", "ShorelineType"))
allformulas <- allformulas[2:length(allformulas)] #i dont want the intercept only one 
```

now pass these formulas through a for loop in a cross validation - lets say we want this to repeat 100 times

```{r}
set.seed(123)
compare_var <- as.data.frame(matrix(ncol = 4, nrow = 0))
colnames(compare_var) <- c("formula", "RMSE", "R2", "MAE")

for ( i in 1:length(allformulas)) {
  
train.control <- trainControl(method = "repeatedcv", number = 3, repeats = 5) #should be 100
# Train the full model

##CHANGE THIS! 
model_full <- train(as.formula(allformulas[i]), data = df_count_wide, method = "lm",trControl = train.control)

model_full <- train(as.formula(allformulas[i]), data = df_count_wide, method = "lm",trControl = train.control)


# Summarize the results
compare_var[i, 1] <- allformulas[i]
compare_var[i, 2] <- mean(model_full$resample$RMSE)
compare_var[i, 3] <- mean(model_full$resample$Rsquared, na.rm = T)
compare_var[i, 4] <- mean(model_full$resample$MAE)


}

compare_var$prediction_error_rate <- compare_var$RMSE/mean(df_CPUE_wide_train$red_drum) 

compare_var %>% arrange(prediction_error_rate)

compare_var %>% arrange(RMSE)


avg_depth+SAVDist_km+InletDist_km+atlantic_menhaden+southern_floun

gam_formula_CV <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) 
tweedie_CV <- gam(gam_formula_CV, family= tw(link= "log"), data= df_count_wide_train, method= "REML")
summary(tweedie_CV)
```
