---
title: "CARTs"
format: html
editor: visual
---

Model description from Sarah Roberts, professor of UNC-CH BIOL 562: Statistics for Environmental Scientists

#### Load packages, functions, and datasets

```{r}
#Load packages and functions 
packages <- c("ggplot2", "tidyverse", "lubridate", "sf", "sp", "dplyr", "rnaturalearth", "readr", "readxl", "spatialEco", "rstatix", "viridis", "BBmisc", "corrplot", "mgcv", "GGally")

invisible(lapply(packages, library, character.only= TRUE))

standard_theme <- theme_bw() + theme(panel.border = element_rect(fill=NA, colour = "black")) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(legend.text.align= 0, legend.title= element_text(size = 12), legend.text = element_text(size= 10), axis.text=element_text(size=10), axis.title=element_text(size=12))

#Load in datasets
##Standardized catch per unit effort 
CPUE_grid_avg_edt <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.csv")
CPUE_grid_avg_edt <- CPUE_grid_avg_edt[,-1]
CPUE_grid_avg_edt <- CPUE_grid_avg_edt %>% mutate_at(c("Sedsize_common", "ShorelineType", "ITP", "Survey"), as.factor)
CPUE_grid_avg_edt$Speciescommonname <- gsub(" ", "_", CPUE_grid_avg_edt$Speciescommonname)

##Count dataset 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd)) #need to remove or R will get confused 
df_count$Speciescommonname <- gsub(" ", "_", df_count$Speciescommonname)

#Pivot-wider datasets: 
##Standardized catch per unit effort dataset wide 
df_CPUE_wide <- CPUE_grid_avg_edt %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "mean_CPUE_stdzd") %>% drop_na() #this removes three rows where NAs were present, feel comfortable doing this b/c a lot of most species had at least 1 NA (some 2), could be an issue from pulling the data or 

##Binary dataset (0 or 1):  
df_binary_wide <- df_CPUE_wide %>% mutate_at(vars(15:41), ~ ifelse(. > 0, 1, 0))

##Count dataset wide 
df_count_wide <- df_count %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

#Form train/testing datasets by dividing 80% 20% 
set.seed(777)
##Randomly split data in R
sample_size = floor(0.8*nrow(df_CPUE_wide)) #take 80% of rows, # is same b/w dfs

##CPUE model
picked_CPUE = sample(seq_len(nrow(df_CPUE_wide)),size = sample_size)
df_CPUE_wide_test =df_CPUE_wide[-picked_CPUE,]
df_CPUE_wide_train =df_CPUE_wide[picked_CPUE,]

##Binary model
picked_binary = sample(seq_len(nrow(df_binary_wide)),size = sample_size)
df_binary_wide_test = df_binary_wide[-picked_binary,]
df_binary_wide_train = df_binary_wide[picked_binary,]

##Poisson model
picked = sample(seq_len(nrow(df_count_wide)),size = sample_size) 
df_count_wide_test = df_count_wide[-picked,]
df_count_wide_train = df_count_wide[picked,]

#Load GAM formula
gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) + factor(ShorelineType)
```

#### Decision trees

"Decision trees, as their name conveys, are tree-like diagrams. They work by defining yes-or-no rules based on the data and assign the most common value for each respondent within their final branch. The best way to learn about decision trees is by looking at one."

```{r}
library(tidymodels)
library(tidyflow)
library(devtools)
library(rpart.plot)
library(vip)
library(baguette)
library(ranger)

mod1 <- set_engine(decision_tree(mode = "regression"), "rpart")

tflow <-
  # Plug the data
  df_count_wide %>%
  # Begin the tidyflow
  tidyflow(seed = 23151) %>%
  # Separate the data into training/testing (we are keeping 3/4 of the data for training)
  plug_split(initial_split, prop = 3/4) %>%
  # Plug the formula
  plug_formula(red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common) %>%
  # Plug the model
  plug_model(mod1)

vanilla_fit <- fit(tflow)
tree <- pull_tflow_fit(vanilla_fit)$fit
rpart.plot(tree)
```

#### Bagging:

"Bagging works by bootstraping your data N times and fitting N decision trees. Each of these decision trees has a lot of variance because we allow the tree to overfit the data. The trick with bagging is that we average over the predictions of all the N decision trees, improving the high variability of each single decision tree."

Adding in ShorelineType was throwing this error: All of the models failed. An example message was: Error in `[.data.frame`(m, labs) : undefined columns selected It might be because it has too many categories--\> leave out for now, tried to group two marsh categories and it didn't matter

```{r}
btree <- bag_tree(mode = "regression") %>% set_engine("rpart", times = 50)

tflow2 <-
  df_count_wide %>%
  tidyflow(seed = 566521) %>%
  plug_split(initial_split) %>% plug_formula(red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common) %>%
plug_model(btree)
res_btree <- tflow2 %>% fit()

res_btree
```

#### Random forests:

"If we have a variable that is constantly repeated in every single tree, then the predictions will be very similar. Random Forests are an extension of bagged decision trees because they randomly sample N variables in each split. More specifically, instead of considering all variables in the data, for calculating a given split, random forests pick a random sample of N variables to be considered for that split.

Random Forests differ from decision trees in that instead of evaluating cutoff splits for every variable, they evaluate cutoff splits only for a random sample of N variables. The number of variables N used for each split can be chosen by the user and often it is chosen through a grid search."

For tuning random forest models, you can run sub-models with various tuning parameters to find the best final model. All independent variables are included in the initial formula. This is done through a grid search.

https://cimentadaj.github.io/tidyflow/articles/d04_fitting-model-tuning.html

```{r}
#Standard random forest 
rf_mod <-
  rand_forest(mode = "regression") %>%
  set_engine("ranger", importance = "impurity")

tflow <-
  df_count_wide %>%
  tidyflow(seed = 23151) %>%
  plug_formula(red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common) %>%
  plug_split(initial_split) %>%
  plug_model(rf_mod)

res_rf <- tflow %>% fit()

res_rf %>%
  pull_tflow_fit() %>%
  .[['fit']] %>%
  vip() +
  theme_minimal() #visualize variable importance

#Tune the random forest model
rf_mod <-
  rand_forest(mode = "regression",
       trees = tune()) %>% 
       set_engine("ranger") #tune means trying out different arguments in trees 

tflow <-
 df_count_wide %>% 
  tidyflow(seed = 2151) %>%
  plug_split(initial_split) %>%
  plug_resample(vfold_cv) %>%
  plug_grid(grid_regular, levels = 10) %>% #grid_regular: evenly spaced set of values for trees, specifying 10 resamples, can limit value range of trees (this increase rmse)
  plug_formula(red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common) %>%
  plug_model(rf_mod)

res <- tflow %>% fit() #execute grid search
res %>% pull_tflow_fit_tuning() %>% autoplot() #10 values for 10 resamples
final_mod <- res %>% complete_tflow(metric = "rmse")
final_mod %>%
  predict_training() %>%
  rmse(red_drum, .pred)

pull_tflow_fit(final_mod)

```

#### Boosting:

"The name boosting comes from the notion that we fit a weak decision tree and we 'boost' it iteratively. This strategy is fundamentally different from bagging and random forests because instead of relying on hundreds of independent decision trees, boosting works by recursively boosting the the result of the same decision tree

Basically, boosting starts by fitting a weak tree (i.e with one variable). Boosting works by predicting the residuals of previous decision tree. In our example, we just fitted our first model and calculated the residuals. Boosting works by fitting a second model but the dependent variable should now be the residuals of the first model rather than the math_score variable.

In contrast to random forests, increasing the number of trees in a boosting algorithm can increase overfitting. For the random forest, increasing the number of trees has no impact on overfitting because what we actually get is the average of all these trees. However, for boosting, increasing the number trees means increasing the number of trees that iteratively try to explain residuals. You might reach a point that adding more trees will just try to explain residuals which are random, resulting in overfitting."

```{r}
boost_mod <-
  boost_tree(mode = "regression", trees = 500) %>%
  set_engine("xgboost")

tflow <-
 df_count_wide %>%
  tidyflow(seed = 51231) %>%
  plug_formula(red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common) %>%
  plug_split(initial_split) %>%
  plug_model(boost_mod)

res_boost <- fit(tflow)

res_boost %>%
  pull_tflow_fit() %>%
  .[['fit']] %>%
  vip() +
  theme_minimal() #visualize variable importance



c("Bagged decision trees" = bt_rmse,
  "Random Forest" = rf_rmse,
  "Extreme Gradient Boosting" = gb_rmse)

boost_mod <- update(boost_mod, stop_iter = 20)

tflow <-
  tflow %>%
  replace_model(boost_mod)

res_boost_updated <- fit(tflow)


res_boost_updated %>%
  pull_tflow_fit() %>%
  .[['fit']] %>%
  vip() +
  theme_minimal() #visualize variable importance
```

#### Compare

A low RMSE, or a root mean square error, means that the distance between predictions and the true values is low.

```{r}
#In-sample (training) comparison 
vanilla_fit_rmse <- vanilla_fit %>%
  predict_training() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_btree_rmse <-  res_btree %>%
  predict_training() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_rf_rmse <- res_rf %>%
  predict_training() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_boost_rmse <-
  res_boost %>%
  predict_training() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_boost_updated_rmse <-
  res_boost_updated %>%
  predict_training() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

c("Bagged decision trees" = res_btree_rmse,
  "Random Forest" = res_rf_rmse,
  "Extreme Gradient Boosting" = res_boost_rmse, "Extreme Gradient Boosting Mod"= res_boost_updated_rmse)

#Out of sample (testing) comparison 
vanilla_fit_rmse_test <- vanilla_fit %>%
  predict_testing() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_btree_rmse_test <-  res_btree %>%
  predict_testing() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_rf_rmse_test <- res_rf %>%
  predict_testing() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_boost_rmse_test <-
  res_boost %>%
  predict_testing() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

res_boost_updated_rmse_test <-
  res_boost_updated %>%
  predict_testing() %>%
  rmse(red_drum, .pred) %>%
  pull(.estimate)

c("Bagged decision trees" = res_btree_rmse_test,
  "Random Forest" = res_rf_rmse_test,
  "Extreme Gradient Boosting" = res_boost_rmse_test, "Extreme Gradient Boosting Mod"= res_boost_updated_rmse_test)
```
