---
title: "Tuning"
format: html
editor: visual
---

Tune tweedie and poisson GAM using caret() package in R for different variables and values for k either write a for loop, tidy models Take tweedie GAM, go through and try different types of cross-validation (leave 1 out, 70/30), tune as you go (removing variable), find the best K, focus on one distribution that makes sense, do it with tidymodels For loop to try different parameters and for loop to try different k values, maybe 3 for loops to select random 70 and train/test on 30

#### Load packages, functions, and datasets

```{r}
##Remove sheepshead from analysis!!
#Remove InletDist or SAVDist_km 

#Load packages and functions 
packages <- c("ggplot2", "tidyverse", "lubridate", "sf", "sp", "dplyr", "rnaturalearth", "readr", "readxl", "spatialEco", "rstatix", "viridis", "BBmisc", "corrplot", "mgcv", "GGally", "gjam", "report")
invisible(lapply(packages, library, character.only= TRUE))

library(lmtest)
library(countreg)
library(gridExtra)
library(ggplot2)
library(MASS)
library(countreg)
library(performance)
library(tidymodels)
library(tidyflow)
library(devtools)
library(rpart.plot)
library(vip)
library(baguette)
library(ranger)

standard_theme <- theme_bw() + theme(panel.border = element_rect(fill=NA, colour = "black")) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(legend.text.align= 0, legend.title= element_text(size = 12), legend.text = element_text(size= 10), axis.text=element_text(size=10), axis.title=element_text(size=12))

#Load in datasets
##Standardized catch per unit effort 
CPUE_grid_avg_edt <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.csv")
CPUE_grid_avg_edt <- CPUE_grid_avg_edt[,-1]
CPUE_grid_avg_edt <- CPUE_grid_avg_edt %>% mutate_at(c("Sedsize_common", "ShorelineType", "ITP", "Survey"), as.factor)
CPUE_grid_avg_edt$Speciescommonname <- gsub(" ", "_", CPUE_grid_avg_edt$Speciescommonname)

##Count dataset 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd)) #need to remove or R will get confused 
df_count$Speciescommonname <- gsub(" ", "", df_count$Speciescommonname)

#Pivot-wider datasets: 
##Standardized catch per unit effort dataset wide 
df_CPUE_wide <- CPUE_grid_avg_edt %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "mean_CPUE_stdzd") %>% drop_na() #this removes three rows where NAs were present, feel comfortable doing this b/c a lot of most species had at least 1 NA (some 2), could be an issue from pulling the data or 

##Binary dataset (0 or 1):  
df_binary_wide <- df_CPUE_wide %>% mutate_at(vars(15:41), ~ ifelse(. > 0, 1, 0))

##Count dataset wide 
df_count_wide <- df_count %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

#Form train/testing datasets by dividing 80% 20% 
set.seed(777)
##Randomly split data in R
sample_size = floor(0.8*nrow(df_CPUE_wide)) #take 80% of rows, # is same b/w dfs

##CPUE model
picked_CPUE = sample(seq_len(nrow(df_CPUE_wide)),size = sample_size)
df_CPUE_wide_test =df_CPUE_wide[-picked_CPUE,]
df_CPUE_wide_train =df_CPUE_wide[picked_CPUE,]

##Binary model
picked_binary = sample(seq_len(nrow(df_binary_wide)),size = sample_size)
df_binary_wide_test = df_binary_wide[-picked_binary,]
df_binary_wide_train = df_binary_wide[picked_binary,]

##Poisson model
picked = sample(seq_len(nrow(df_count_wide)),size = sample_size) 
df_count_wide_test = df_count_wide[-picked,]
df_count_wide_train = df_count_wide[picked,]

#Load in formulas  
##Load GAM formula
gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) #no shoreline type b/c was weird w/ CART

##Other 
model_formula <- red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common

#5 km 
#Load in datasets
##Standardized catch per unit effort 
CPUE_grid_avg_edt_5km <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.5km.10.04.23.csv")
CPUE_grid_avg_edt_5km <- CPUE_grid_avg_edt_5km[,-1]
CPUE_grid_avg_edt_5km <- CPUE_grid_avg_edt_5km %>% mutate_at(c("Sedsize_common", "ShorelineType", "Survey"), as.factor) %>% rename("SAVDist_km"= "SAV_km")
CPUE_grid_avg_edt_5km$Speciescommonname <- gsub(" ", "_", CPUE_grid_avg_edt_5km$Speciescommonname)

##Count dataset 
df_count_5km <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.5km.10.04.23.csv")  
df_count_5km <- df_count_5km %>% dplyr::select(-c(...1, CPUE:mean_CPUE_stdzd)) %>% rename("SAVDist_km"= "SAV_km") #need to remove or R will get confused 
df_count_5km$Speciescommonname <- gsub(" ", "_", df_count_5km$Speciescommonname)

#Pivot-wider datasets: 
##Standardized catch per unit effort dataset wide 
df_CPUE_wide_5km <- CPUE_grid_avg_edt_5km %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "mean_CPUE_stdzd") %>% drop_na() #this removes three rows where NAs were present, feel comfortable doing this b/c a lot of most species had at least 1 NA (some 2), could be an issue from pulling the data or 

##Binary dataset (0 or 1):  
df_binary_wide_5km <- df_CPUE_wide_5km %>% mutate_at(vars(15:41), ~ ifelse(. > 0, 1, 0))

##Count dataset wide 
df_count_wide_5km <- df_count_5km %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

#Form train/testing datasets by dividing 80% 20% 
set.seed(777)
##Randomly split data in R
sample_size_5km = floor(0.8*nrow(df_CPUE_wide_5km)) #take 80% of rows, # is same b/w dfs

##CPUE model
picked_CPUE_5km = sample(seq_len(nrow(df_CPUE_wide_5km)),size = sample_size_5km)
df_CPUE_wide_test_5km =df_CPUE_wide_5km[-picked_CPUE_5km,]
df_CPUE_wide_train_5km =df_CPUE_wide_5km[picked_CPUE_5km,]

##Binary model
picked_binary_5km = sample(seq_len(nrow(df_binary_wide_5km)),size = sample_size_5km)
df_binary_wide_test_5km = df_binary_wide_5km[-picked_binary_5km,]
df_binary_wide_train_5km = df_binary_wide_5km[picked_binary_5km,]

##Poisson model
picked_5km = sample(seq_len(nrow(df_count_wide_5km)),size = sample_size_5km) 
df_count_wide_test_5km = df_count_wide_5km[-picked_5km,]
df_count_wide_train_5km = df_count_wide_5km[picked_5km,]
```

#### Load cross-validation functions

```{r}
library(gtools)

pastePerm<- function(row, names){
  keep<- which(row==1)
  if(length(keep)==0){
    return('1')
  }else{
    return(paste(names[keep],collapse='+'))
  }
}
my_sqrt <- function(var1){
  sqrt(var1) #take square root of variable 
} #construct model formulas 

dredgeform<- function(pred, covars, alwaysIn=''){ #always in is set to empty string
  p<- length(covars) #number of independent variables
  perm.tab<- permutations(2, p, v=c(0,1), repeats.allowed=T) #for different combinations of predictor variables
  myforms<- NULL #store formulas 
  for(j in 1:nrow(perm.tab)){
    myforms[j]<- pastePerm(perm.tab[j,], covars) #function above
  }
  myforms<- paste0(pred, '~',myforms) #predicted variable and formula
  return(myforms)
}

allformulas <- dredgeform(pred = "red_drum", covars = c("s(avg_depth, bs= 'ts', k= 10)", "s(avg_sdo, bs= 'ts', k= 10)", "s(SAVDist_km, bs= 'ts', k= 10)", "s(InletDist_km, bs= 'ts', k= 10)", "s(NoFishRest, bs= 'ts', k= 10)", "s(atlantic_menhaden, bs= 'ts', k= 10)", "s(atlantic_croaker, bs= 'ts', k= 10)", "s(southern_flounder, bs= 'ts', k= 10)", "s(spot,bs= 'ts', k= 10)", "factor(FishingAll_num)", "factor(Sedsize_common)"))
```

#### Formula selection

##### Tweedie cross-validation: redoing it with k= 10 in all formulas and testing datasets

```{r}
#10 km
compare_var_tw <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_tw) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {
model_tw <- gam(as.formula(allformulas[i]), family= tw(link= "log"), method= "REML", data=df_count_wide_train)
compare_var_tw[i, 1] <- allformulas[i]
compare_var_tw[i, 2] <- AIC(model_tw)
}

tw_k10 <- gam(reddrum~ s(SAVDist_km, bs= 'ts', k= 10)+s(InletDist_km, bs= 'ts', k= 10)+ s(atlanticmenhaden, bs= 'ts', k= 10)+factor(FishingAll_num)+factor(Sedsize_common), family= tw(link= "log"), method= "REML", data= df_count_wide_train)
summary(tw_k10)
gam.check(tw_k10)
tw_k10_pred <- predict(tw_k10, newdata = df_count_wide_train, type = "response")
 pois <- as.data.frame(matrix(ncol =3))
    pois$V1 <- "pois"
    pois$V2 <- r2_func(tw_k10_pred, df_count_wide_test$red_drum)
    pois$V3 <- RMSE_func(tw_k10_pred, df_count_wide_test$red_drum)
colnames(pois) <- c("model_type", "R2", "RMSE")

# model_tw_picked_10km_k5 <- gam(red_drum~ s(avg_depth, k=5) + s(avg_stemp, k= 5) + s(atlantic_menhaden, k=5) + s(SAVDist_km, k=5) + Sedsize_common, family= tw(link= "log"), method= "REML", data=df_count_wide_5km)
# summary(model_tw_picked)
# 
# model_tw_picked_10km_k10 <- gam(red_drum~ s(avg_depth, k=5) + s(avg_stemp, k= 5) + s(atlantic_menhaden, k=5) + s(SAVDist_km, k=5) + Sedsize_common, family= tw(link= "log"), method= "REML", data=df_count_wide_5km)
# summary(model_tw_picked)
# 
# model_tw_picked2 <- gam(red_drum~ s(avg_depth, k=5) + s(avg_stemp, k= 5) + s(atlantic_menhaden, k=5) + s(SAVDist_km, k=5) + Sedsize_common, family= tw(link= "log"), method= "REML", data=df_count_wide)
# summary(model_tw_picked)

#5 km
compare_var_tw5 <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_tw5) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {
model_tw5 <- gam(as.formula(allformulas[i]), family= tw(link= "log"), method= "REML", data=df_count_wide_train_5km)
compare_var_tw5[i, 1] <- allformulas[i]
compare_var_tw5[i, 2] <- AIC(model_tw5)
}


tw_k10_5km <- gam(red_drum~s(avg_depth, bs= 'ts', k= 10)+s(InletDist_km, bs= 'ts', k= 10)+s(atlantic_menhaden, bs= 'ts', k= 10)+s(southern_flounder, bs= 'ts', k= 10), family= tw(link= "log"), method= "REML", data= df_count_wide_train_5km)
summary(tw_k10_5km)
gam.check(tw_k10_5km)

# model_tw5_picked <- gam(red_drum~ s(avg_depth, k=5) + s(InletDist_km, k= 5) + s(atlantic_menhaden, k=5) + s(southern_flounder, k=5) + FishingAll_num, family= tw(link= "log"), method= "REML", data=df_count_wide_5km)
# summary(model_tw5_picked)

```

##### Poisson GAM cross-validation

Dealing with overfitting: https://statisticsbyjim.com/regression/overfitting-regression-models/

```{r}
#10 km
compare_var_pg <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_pg) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {
model_pg <- gam(as.formula(allformulas[i]), family= poisson(), method= "REML", data=df_count_wide)
compare_var_pg[i, 1] <- allformulas[i]
compare_var_pg[i, 2] <- AIC(model_pg)
}

model_picked_10 <- gam(reddrum~s(avg_depth, bs= 'ts', k= 10)+s(avg_sdo, bs= 'ts', k= 10)+s(SAVDist_km, bs= 'ts', k= 10)+s(InletDist_km, bs= 'ts', k= 10)+s(NoFishRest, bs= 'ts', k= 10)+s(atlanticmenhaden, bs= 'ts', k= 10)+s(atlanticcroaker, bs= 'ts', k= 10)+s(spot,bs= 'ts', k= 10)+factor(FishingAll_num), family= poisson(), method= "REML", data=df_count_wide)
summary(model_picked_10)
gam.check(model_picked_10)

model_pg_picked <- gam(reddrum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlanticmenhaden, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide_train)
summary(model_pg_picked)
gam.check(model_pg_picked)
report(model_pg_picked)
pois_pred <- predict(model_pg_picked, newdata = df_count_wide_test, type = "response")
 pois <- as.data.frame(matrix(ncol =3))
    pois$V1 <- "pois"
    pois$V2 <- r2_func(pois_pred, df_count_wide_test$reddrum)
    pois$V3 <- RMSE_func(pois_pred, df_count_wide_test$reddrum)
colnames(pois) <- c("model_type", "R2", "RMSE")

AIC(model_tw_picked, model_tw_picked2, model_pg_picked, model_pg5_picked, model_picked_10)
?gam()
#	If this is TRUE then gam can add an extra penalty to each term so that it can be penalized to zero. This means that the smoothing parameter estimation that is part of fitting can completely remove terms from the model. If the corresponding smoothing parameter is estimated as zero then the extra penalty has no effect. Use gamma to increase level of penalization.

#5km
compare_var_pg5 <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_pg5) <- c("formula", "AIC")

for (i in 1:length(allformulas)) {
model_pg5 <- gam(as.formula(allformulas[i]), family= poisson(), method= "REML", data=df_count_wide_5km)
compare_var_pg5[i, 1] <- allformulas[i]
compare_var_pg5[i, 2] <- AIC(model_pg5)
}

compare_var_pg5 %>% arrange(AIC)

model_pg5_picked <- gam(red_drum~s(avg_depth, bs= 'ts', k= 10)+s(avg_sdo, bs= 'ts', k= 10)+s(SAVDist_km, bs= 'ts', k= 10)+s(InletDist_km, bs= 'ts', k= 10)+s(NoFishRest, bs= 'ts', k= 10)+s(atlantic_menhaden, bs= 'ts', k= 10)+s(atlantic_croaker, bs= 'ts', k= 10)+s(southern_flounder, bs= 'ts', k= 10)+s(spot,bs= 'ts', k= 10)+factor(FishingAll_num), family= poisson(), method= "REML", data= df_count_wide_train_5km)

summary(model_pg5_picked)
gam.check(model_pg5_picked)
report(model_pg5_picked)

pois_pred <- predict(model_pg5_picked, newdata = df_count_wide_test_5km, type = "response")
 pois <- as.data.frame(matrix(ncol =3))
    pois$V1 <- "pois"
    pois$V2 <- r2_func(pois_pred, df_count_wide_test$red_drum)
    pois$V3 <- RMSE_func(pois_pred, df_count_wide_test$red_drum)
colnames(pois) <- c("model_type", "R2", "RMSE")
```

###With multiple datasets

```{r}
#Organize data 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd)) #need to remove or R will get confused 
df_count$Speciescommonname <- gsub(" ", "", df_count$Speciescommonname)
df_count$SpeciesSurvey <- paste(df_count$Speciescommonname, df_count$Survey, sep= "")

df_count_wide2 <- df_count %>% dplyr::select(-Speciescommonname, -Survey) %>% ungroup() %>% pivot_wider(names_from = "SpeciesSurvey", values_from = "avg_count") #%>% drop_na()

df_count_wide_na <- df_count %>% filter(Survey %in% "P915"|Survey %in% "P120") %>% dplyr::select(-Speciescommonname, -Survey) %>% ungroup() %>% pivot_wider(names_from = "SpeciesSurvey", values_from = "avg_count") %>% drop_na()
#87 gridIDs with data from all species 
#143 for P915 and P195
#281 b/w P120 and P915

smp_size_na <- floor(0.70 * nrow(df_count_wide_na)) #this is how i want to split training and testing data 

allformulas <- dredgeform(pred = "red_drum", covars = c("s(avg_depth, bs="ts", k= 10)", "s(avg_sdo, k= 10)", "s(SAVDist_km, k= 10)", "s(InletDist_km, k= 10)", "s(NoFishRest, k= 10)", "s(atlantic_menhaden, k= 10)", "s(atlantic_croaker, k= 10)", "s(southern_flounder, k= 10)", "s(spot, k= 10)", "factor(FishingAll_num)", "factor(Sedsize_common)", "s(blue_crab_P120"))


red_drum_P915 ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden_P915, bs="ts", k=5) + s(atlantic_croaker_P915, bs="ts", k=5) + s(southern_flounder_P915, bs="ts", k=5) + s(spot_P915, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) + s(blue_crab_P120, bs="ts", k=5) + s(weakfish_P120, bs="ts", k=5) + s(brown_shrimp_P120, bs="ts", k=5) + s(atlantic_menhaden_P120, bs="ts", k=5) + s(atlantic_croaker_P120, bs="ts", k=5) + s(pinfish_P120, bs="ts", k=5) + s(pink_shrimp_P120, bs="ts", k=5) + s(southern_flounder_P120, bs="ts", k=5) + s(spot_P120, bs="ts", k=5)
```

```{r}
set.seed(123)
compare_var <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {

model <- gam(as.formula(allformulas[i]), data = cities_df, family = "binomial"(link= logit))

# Summarize the results
compare_var[i, 1] <- allformulas[i]
compare_var[i, 2] <- AIC(model)
}

compare_var %>% arrange(AIC)
```

```{r}
set.seed(123)
library(caret)
compare_var <- as.data.frame(matrix(ncol = 4, nrow = 0))
colnames(compare_var) <- c("formula", "AUC", "sensitivity", "specificity")

for ( i in 2:length(allformulas)) {
  
train.control <- trainControl(method = "repeatedcv", number = 3, repeats = 10, 
                     summaryFunction=twoClassSummary, 
                     classProbs=T,
                     savePredictions = T)

# Train the full model
model <- train(as.formula(allformulas[i]), data = df_count_wide, method = "gam", family = "binomial", trControl = train.control, metric = "ROC")

# Summarize the results
compare_var[i, 1] <- allformulas[i]
compare_var[i, 2] <- model$results$ROC
compare_var[i, 3] <- model$results$Sens
compare_var[i, 4] <- model$results$Spec


}

compare_var %>% arrange(-AUC)
```

```{r}
model_pg5_picked <- gam(red_drum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide_5km)

tester <- gam(red_drum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide_5km, select= TRUE)

summary(model_pg5_picked)
summary(tester)

gam.check(model_pg5_picked)
gam.check(tester)
```

##### gJam:

gJam: include variables that make ecological sense, dolphin code: cross-validation like bootstrapping- run 1,000 times, get an average of the samples, look at dolphin code, split 70 and 30 in the bootstrap instead of randomly select prey, she randomly selected prey: testing if model w/ prey was better w/ just environment, 4 environmental variables and wanted to select 4 prey randomley out of the 20

```{r}
df_count$SpeciesSurvey <- paste(df_count$Speciescommonname, df_count$Survey, sep= "")
colnames(df_count) <- gsub(pattern = "_", replacement = "", colnames(df_count))
df_count_wide_edt <- df_count %>% dplyr::select(-Speciescommonname, -Survey) %>% ungroup() %>% pivot_wider(names_from = "SpeciesSurvey", values_from = "avgcount")

df_count_wide_na <- df_count %>% filter(Survey %in% "P915"|Survey %in% "P120") %>% dplyr::select(-Speciescommonname, -Survey) %>% ungroup() %>% pivot_wider(names_from = "SpeciesSurvey", values_from = "avgcount") %>% drop_na()

##xdata: Environmental variables
# xdata <- df_count_wide_na %>% dplyr::select(avg_depth, avg_stemp, avg_ssal, avg_sdo, SAVDist_km, InletDist_km, NoFishRest,  FishingAll_num, Sedsize_common, alewife.P915:white.shrimp.P120, -(c(red.drum.P915, bonnethead.shark.P915, black.drum.P915, cownose.ray.P915, southern.kingfish.P915, striped.bass.P915))) %>% mutate_at(vars(Sedsize_common), as.factor)
# colnames(xdata) <- gsub(pattern = "_", replacement = ".", colnames(xdata))

xdata <- df_count_wide_na %>% dplyr::select(avgdepth, avgstemp, avgssal, avgsdo, SAVDistkm, InletDistkm, NoFishRest, FishingAllnum, Sedsizecommon) %>% mutate_at(vars(c(Sedsizecommon, FishingAllnum)), as.factor)

##ydata: species of interest, same dimensions as xdata 
ydata <- df_count_wide_na %>% dplyr::select(alewifeP915:whiteshrimpP120) 

species  <- gjamTrimY(ydata, 50, OTHER = FALSE)$y %>% colnames() #minimum # of non-zero observations: 20 
ydata <- ydata[, species] %>% as.data.frame()

##edata: effort, columns as number of species and values as effort values  
edata <- list(columns=1:ncol(ydata), values = 1)

edata$columns
edata$values
```

gjam can predict a subset of columns in y conditional on other columns using the function gjamPredict.

The conditional prediction can differ from the unconditional one, due to the covariances between species.

```{r}
Bootstrap_times <- 100
smp_size <- floor(0.70 * nrow(df_count_wide_na))

gjam_test <- data.frame(matrix(ncol=8, nrow=1))
colnames(gjam_test) <- c("r2_con", "r2_uncon", "rmse_con", "rmse_uncon","fish1", "fish2", "fish3", "fish4" ) #creating dataframe where 


modo <- gjam(~ avgstemp + avgssal + avgsdo, xdata = xdata, ydata = ydata, modelList = ml) 
 
# unconditionally predict in-sample
modo <- gjam(~ avgstemp + avgssal + avgsdo, xdata = xdata, ydata = ydata, modelList = ml)


cor <- modo[["parameters"]][["corMu"]] #residual correlation calculated from modo, modo as model
resid <- as.data.frame(cor)
resid$names <- rownames(cor)
resid <- resid %>% dplyr::select(reddrumP915,names) %>% dplyr::filter(names!= reddrumP915)




for(i in 1:Bootstrap_times) {
  train_ind <- sample(seq_len(nrow(df_count_wide_na)), size = smp_size)
  train <- df_count_wide_na[train_ind, ]
  test <- df_count_wide_na[-train_ind, ]

#randomly select fish to use to predict
  use <- resid %>% top_n(15, reddrumP915) #Sarah did this for all species, idk how her data was setup, let's try to do this for one predator of focus 
fish <- sample(use$names, 4, replace = F)
specs1 <- fish
ynames <- c(specs1, "reddrumP915")
ydata_train <- train[,colnames(train) %in% ynames]
xdata_train <- train %>% dplyr::select(avgstemp, avgssal, avgsdo)
ydata_train <- ydata_train[,colSums(ydata_train != 0) > 5] # I want non-zero rows
ynames <- colnames(ydata_train)

ml <- list(ng = 60000, burnin = 50000, typeNames = 'DA')

mod2 <- gjam(~ avgstemp + avgssal + avgsdo, xdata = xdata_train, ydata = ydata_train, modelList = ml) #removed effort

xdata_test <- test %>% dplyr::select(avgstemp, avgssal, avgsdo)
ydata_test <- test[,colnames(test) %in% ynames]

ycond <- ydata_test %>% dplyr::select(-reddrumP915) #just remove red drum

newdata1 <- list(xdata = xdata_test, ydataCond= ycond, nsim = 1000) # conditionally predict in-sample

p6 <- gjamPredict(mod2, newdata = newdata1)
view(gjamPredict)
#output: gjam model w/ 4 prey items 
#data for prediction 
#if specify new data, it is either conditional or out of sample
pred_dolph_con <- p6$sdList$yMu[,colnames(p6$sdList$yMu) %in% "AbdPerArea"] #get out dolph
obs_dolph <- ydata_test[,colnames(ydata_test) %in% "AbdPerArea"]#observed dolph
#colnames(obs_dolph) <- "obs_dolph"

newdata2 <- list(xdata = xdata_test, nsim = 1000) # unconditionally prediction- in-sample

p7 <- gjamPredict(mod2, newdata = newdata2)
pred_dolph_un <- p7$sdList$yMu[,colnames(p7$sdList$yMu) %in% "AbdPerArea"]
pred_dolph_un2 <- mod2$prediction$ypredMu[,colnames(mod2$prediction$ypredMu) %in% "AbdPerArea"]

dat <- cbind(pred_dolph_con, obs_dolph, pred_dolph_un)
dat <- as.data.frame(dat)

r2_con_fall <- r2_general(dat$pred_dolph_con, dat$obs_dolph)
r2_uncon_fall <- r2_general(dat$pred_dolph_un, dat$obs_dolph)
rmse_con_fall <-  RMSE_func(actual = dat$obs_dolph, pred = dat$pred_dolph_con)
rmse_uncon_fall <-  RMSE_func(actual = dat$obs_dolph, pred = dat$pred_dolph_un)

offshore_out_perform_gjam[i,1] <- r2_con_fall
offshore_out_perform_gjam[i,2] <- r2_uncon_fall
offshore_out_perform_gjam[i,3] <- rmse_con_fall
offshore_out_perform_gjam[i,4] <- rmse_uncon_fall

offshore_out_perform_gjam[i,5] <- fish[1]
offshore_out_perform_gjam[i,6] <- fish[2]
offshore_out_perform_gjam[i,7] <- fish[3]
offshore_out_perform_gjam[i,8] <- fish[4]


}
summary(offshore_out_perform_gjam[1:4])
```

```{r}
#Functions
pastePerm<- function(row, names){
  keep<- which(row==1)
  if(length(keep)==0){
    return('1')
  }else{
    return(paste(names[keep],collapse='+'))
  }
}
dredgeGJAM<- function(covars, alwaysIn=''){
  p<- length(covars)
  perm.tab<- permutations(2, p, v=c(0,1), repeats.allowed=T)
  myforms<- NULL
  for(j in 1:nrow(perm.tab)){
    myforms[j]<- pastePerm(perm.tab[j,], covars)
  }
  myforms<- paste0('~', alwaysIn,'+', myforms)
  return(myforms)
}
library(gtools)

r2_general <-function(preds,actual){ 
  return(1- sum((preds - actual) ^ 2)/sum((actual - mean(actual))^2))
}

RMSE_func <- function(preds, actual){
  return(sqrt(mean((actual - preds)^2)))
         }
```

```{r}
#Setup data
#Count dataset 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd))
df_count$Speciescommonname <- gsub(" ", ".", df_count$Speciescommonname) #gJam doesn't like _ in column names

##Standardized catch per unit effort 
CPUE_grid_avg_edt <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.csv")
CPUE_grid_avg_edt <- CPUE_grid_avg_edt[,-1]
CPUE_grid_avg_edt <- CPUE_grid_avg_edt %>% mutate_at(c("Sedsize_common", "ShorelineType", "ITP", "Survey"), as.factor)
CPUE_grid_avg_edt$Speciescommonname <- gsub(" ", ".", CPUE_grid_avg_edt$Speciescommonname)

df_count_wide <- df_count %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

xdata <- df_count_wide %>% dplyr::select(avg_depth, avg_stemp, avg_ssal, avg_sdo, SAVDist_km, InletDist_km, NoFishRest,  FishingAll_num, Sedsize_common) %>% mutate_at(vars(c(Sedsize_common, FishingAll_num)), as.factor)
colnames(xdata) <- gsub(pattern = "_", replacement = ".", colnames(xdata))

##ydata: species of interest, same dimensions as xdata 
ydata <- df_count_wide %>% dplyr::select(american.shad, atlantic.thread.herring:bonnethead.shark, bull.shark:cownose.ray, gizzard.shad:atlantic.sharpnose.shark, silver.perch:summer.flounder, -silversides)

##edata: effort, columns as number of species and values as effort values  
edata <- list(columns=1:ncol(ydata), values = 1)

tot <- cbind(xdata, ydata)
```

```{r}
#Tuning for gJam: Code from GFW_manuscript.Rmd, Sarah Roberts
smp_size <- floor(0.70 * nrow(tot))
set.seed(123)
train_ind <- sample(seq_len(nrow(tot)), size = smp_size)
train <- tot[train_ind, ]
test <- tot[-train_ind, ]

colnames(xdata)
xnames <- c("avg.depth", "avg.stemp", "avg.ssal", "avg.sdo", "SAVDist.km", "InletDist.km", "NoFishRest", "FishingAll.num",  "Sedsize.common")

xdata <- train[,xnames] #training xdata
xdata <- as.data.frame(xdata)
ydata <- train[,colnames(ydata)]
ml <- list(ng = 100, burnin = 40, typeNames = 'DA', effort= edata)

#find all possible interactions and variables
xdata2 <- train[,c("avg.depth", "avg.stemp", "avg.ssal", "avg.sdo", "SAVDist.km", "InletDist.km", "NoFishRest", "FishingAll.num",  "Sedsize.common")]
inter <- model.matrix( ~.^2, data=xdata2) #create interactions
covars <- colnames(inter)
covars <- covars[c(2, 6,7, 9,10,11,37)] #select covars you're interested in
covars <- c(covars)
allformulas<- dredgeGJAM(covars, alwaysIn='avg.stemp + avg.ssal + avg.sdo')
allformulas <- gsub(pattern = ":", replacement = "*", allformulas)

savestuff<- as.data.frame(matrix(NA, length(allformulas), 15))

colnames(savestuff) = c("Formula", "DIC", "R2", "RMSE", "Mean_obs", "R2fishing", "R2trawlers","R2pole","R2pots","R2gillnets", "RMSEfishing", "RMSEtrawlers","RMSEpole","RMSEpots","RMSEgillnets")
```

```{r}
smp_size <- floor(0.70 * nrow(df_count_wide_na))
#run outside of the for loop to diagnose the prob
ml <- list(ng = 1000, burnin = 500, typeNames = 'DA')

# unconditionally predict in-sample
modo <- gjam(~ avgstemp + avgssal + avgsdo, xdata = xdata, ydata = ydata, modelList = ml)

newdata1 <- list(xdata = xdata, nsim = 1000)
p6 <- gjamPredict(modo, newdata = newdata1)

# conditionally predict in-sample
modo <- gjam(~ avgstemp + avgssal + avgsdo, xdata = xdata, ydata = ydata, modelList = ml)
ycond <- ydata %>% dplyr::select(-reddrumP915) #just remove red drum

newdata1 <- list(xdata = xdata, ydataCond= ycond, nsim = 1000)
p6 <- gjamPredict(modo, newdata = newdata1)

#predict on new data (out of sample)
total <- cbind(ydata, xdata)
train_ind <- sample(seq_len(nrow(total)), size = smp_size)
train <- total[train_ind, ]
test <- total[-train_ind, ]

#randomly select fish to use to predict
ydata_train <- train[,colnames(train) %in% species]
xdata_train <- train %>% dplyr::select(avgdepth, avgstemp, avgssal, avgsdo, SAVDistkm, InletDistkm, NoFishRest,  FishingAllnum, Sedsizecommon) %>% mutate_at(vars(c(Sedsizecommon, FishingAllnum)), as.factor)
ydata_train <- ydata_train[,colSums(ydata_train != 0) > 5] # I want non-zero rows
ynames <- colnames(ydata_train)
xdata_test <- test %>% dplyr::select(avgdepth, avgstemp, avgssal, avgsdo, SAVDistkm, InletDistkm, NoFishRest,  FishingAllnum, Sedsizecommon) %>% mutate_at(vars(c(Sedsizecommon, FishingAllnum)), as.factor)
ydata_test <- test[,colnames(test) %in% ynames]


# unconditionally predict out of-sample
modo <- gjam(~ avgstemp + avgssal + avgsdo, xdata = xdata_train, ydata = ydata_train, modelList = ml)

newdata1 <- list(xdata = xdata_test, nsim = 1000)
p6 <- gjamPredict(modo, newdata = newdata1)


# conditionally predict out of-sample
ycond <- ydata_test %>% dplyr::select(-reddrumP915) #just remove red drum
newdata1 <- list(xdata = xdata_test, ydataCond= ycond, nsim = 1000)
p6 <- gjamPredict(modo, newdata = newdata1) 
```

```{r}
#Run gJam
pb <- txtProgressBar(0, length(allformulas), style = 3)
### Out of Sample Prediction Part
test <- test[complete.cases(test),]

    xtest <- test[,xnames]
    xtest <- as.data.frame(xtest)
    ytest <- test[,colnames(ydata)]
    newdata <- list(xdata = xtest, nsim=500)
    
for(M in 1:length(allformulas)){
    tryCatch({
      form <- allformulas[[M]]
    model    <- gjam(form, xdata, ydata, modelList = ml)
    name <- form
    out_of_sample_prediction_non_conditional <- gjamPredict(model, newdata = newdata)
    y_pred <- out_of_sample_prediction_non_conditional$sdList$yMu
    y_obs <- ytest 
    y_pred_long <- as.data.frame(y_pred) %>% pivot_longer(cols = american.shad:summer.flounder, names_to = c("spec"))
    y_obs_long <- as.data.frame(y_obs) %>% pivot_longer(cols =american.shad:summer.flounder, names_to = c("spec"))
    
    tot <- cbind(y_pred_long$value, y_obs_long$value)
    colnames(tot) <- c("pred", "obs")
    tot <- as.data.frame(tot)
colnames(ydata)
    ###
    if(inherits(model, 'try-error'))next
    savestuff[M,1]<- allformulas[[M]]
    savestuff[M,2]<- model$fit$DIC
    savestuff[M,3] <- r2_general(tot$pred, tot$obs)
    savestuff[M,4] <- RMSE_func(actual = tot$obs, pred = tot$pred) 
    savestuff[M,5] <- mean(tot$obs)
    savestuff[M,6] <- r2_general(y_pred[,40], y_obs[,40])
    savestuff[M,7] <- r2_general(y_pred[,41], y_obs[,41])
    savestuff[M,8] <- r2_general(y_pred[,42], y_obs[,42])
    savestuff[M,9] <- r2_general(y_pred[,43], y_obs[,43])
    savestuff[M,10] <- RMSE_func(actual = y_obs[,40], pred = y_pred[,40]) 
    savestuff[M,11] <- RMSE_func(actual = y_obs[,41], pred = y_pred[,41]) 
    savestuff[M,12] <- RMSE_func(actual = y_obs[,42], pred = y_pred[,42]) 
    savestuff[M,13] <- RMSE_func(actual = y_obs[,43], pred = y_pred[,43]) 
    setTxtProgressBar(pb, M)
    Sys.sleep(time = 1)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

write.csv(savestuff, "~/Desktop/modelruns.csv")


#Lowest RMSPE 
```
