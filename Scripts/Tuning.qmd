---
title: "Tuning"
format: html
editor: visual
---

Tune tweedie and poisson GAM using caret() package in R for different variables and values for k either write a for loop, tidy models Take tweedie GAM, go through and try different types of cross-validation (leave 1 out, 70/30), tune as you go (removing variable), find the best K, focus on one distribution that makes sense, do it with tidymodels For loop to try different parameters and for loop to try different k values, maybe 3 for loops to select random 70 and train/test on 30

#### Load packages, functions, and datasets

```{r}
##Remove sheepshead from analysis!!
#Remove InletDist or SAVDist_km 

#Load packages and functions 
packages <- c("ggplot2", "tidyverse", "lubridate", "sf", "sp", "dplyr", "rnaturalearth", "readr", "readxl", "spatialEco", "rstatix", "viridis", "BBmisc", "corrplot", "mgcv", "GGally")

invisible(lapply(packages, library, character.only= TRUE))

library(lmtest)
library(countreg)
library(gridExtra)
library(ggplot2)
library(MASS)
library(countreg)
library(performance)

library(tidymodels)
library(tidyflow)
library(devtools)
library(rpart.plot)
library(vip)
library(baguette)
library(ranger)

standard_theme <- theme_bw() + theme(panel.border = element_rect(fill=NA, colour = "black")) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(legend.text.align= 0, legend.title= element_text(size = 12), legend.text = element_text(size= 10), axis.text=element_text(size=10), axis.title=element_text(size=12))

#Load in datasets
##Standardized catch per unit effort 
CPUE_grid_avg_edt <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.csv")
CPUE_grid_avg_edt <- CPUE_grid_avg_edt[,-1]
CPUE_grid_avg_edt <- CPUE_grid_avg_edt %>% mutate_at(c("Sedsize_common", "ShorelineType", "ITP", "Survey"), as.factor)
CPUE_grid_avg_edt$Speciescommonname <- gsub(" ", "_", CPUE_grid_avg_edt$Speciescommonname)

##Count dataset 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd)) #need to remove or R will get confused 
df_count$Speciescommonname <- gsub(" ", "_", df_count$Speciescommonname)

#Pivot-wider datasets: 
##Standardized catch per unit effort dataset wide 
df_CPUE_wide <- CPUE_grid_avg_edt %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "mean_CPUE_stdzd") %>% drop_na() #this removes three rows where NAs were present, feel comfortable doing this b/c a lot of most species had at least 1 NA (some 2), could be an issue from pulling the data or 

##Binary dataset (0 or 1):  
df_binary_wide <- df_CPUE_wide %>% mutate_at(vars(15:41), ~ ifelse(. > 0, 1, 0))

##Count dataset wide 
df_count_wide <- df_count %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

#Form train/testing datasets by dividing 80% 20% 
set.seed(777)
##Randomly split data in R
sample_size = floor(0.8*nrow(df_CPUE_wide)) #take 80% of rows, # is same b/w dfs

##CPUE model
picked_CPUE = sample(seq_len(nrow(df_CPUE_wide)),size = sample_size)
df_CPUE_wide_test =df_CPUE_wide[-picked_CPUE,]
df_CPUE_wide_train =df_CPUE_wide[picked_CPUE,]

##Binary model
picked_binary = sample(seq_len(nrow(df_binary_wide)),size = sample_size)
df_binary_wide_test = df_binary_wide[-picked_binary,]
df_binary_wide_train = df_binary_wide[picked_binary,]

##Poisson model
picked = sample(seq_len(nrow(df_count_wide)),size = sample_size) 
df_count_wide_test = df_count_wide[-picked,]
df_count_wide_train = df_count_wide[picked,]

#Load in formulas  
##Load GAM formula
gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) #no shoreline type b/c was weird w/ CART

##Other 
model_formula <- red_drum ~ avg_depth + avg_stemp + avg_ssal + avg_sdo + SAVDist_km + InletDist_km + NoFishRest + atlantic_menhaden + atlantic_croaker + southern_flounder + FishingAll_num + Sedsize_common

gam_formula <- red_drum ~ s(avg_depth, bs="ts", k=5) + s(avg_ssal, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common) #no shoreline type b/c was weird w/ CART

#5 km 
#Load in datasets
##Standardized catch per unit effort 
CPUE_grid_avg_edt_5km <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.5km.10.04.23.csv")
CPUE_grid_avg_edt_5km <- CPUE_grid_avg_edt_5km[,-1]
CPUE_grid_avg_edt_5km <- CPUE_grid_avg_edt_5km %>% mutate_at(c("Sedsize_common", "ShorelineType", "Survey"), as.factor) %>% rename("SAVDist_km"= "SAV_km")
CPUE_grid_avg_edt_5km$Speciescommonname <- gsub(" ", "_", CPUE_grid_avg_edt_5km$Speciescommonname)

##Count dataset 
df_count_5km <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.5km.10.04.23.csv")  
df_count_5km <- df_count_5km %>% dplyr::select(-c(...1, CPUE:mean_CPUE_stdzd)) %>% rename("SAVDist_km"= "SAV_km") #need to remove or R will get confused 
df_count_5km$Speciescommonname <- gsub(" ", "_", df_count_5km$Speciescommonname)

#Pivot-wider datasets: 
##Standardized catch per unit effort dataset wide 
df_CPUE_wide_5km <- CPUE_grid_avg_edt_5km %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "mean_CPUE_stdzd") %>% drop_na() #this removes three rows where NAs were present, feel comfortable doing this b/c a lot of most species had at least 1 NA (some 2), could be an issue from pulling the data or 

##Binary dataset (0 or 1):  
df_binary_wide_5km <- df_CPUE_wide_5km %>% mutate_at(vars(15:41), ~ ifelse(. > 0, 1, 0))

##Count dataset wide 
df_count_wide_5km <- df_count_5km %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

#Form train/testing datasets by dividing 80% 20% 
set.seed(777)
##Randomly split data in R
sample_size_5km = floor(0.8*nrow(df_CPUE_wide_5km)) #take 80% of rows, # is same b/w dfs

##CPUE model
picked_CPUE_5km = sample(seq_len(nrow(df_CPUE_wide_5km)),size = sample_size_5km)
df_CPUE_wide_test_5km =df_CPUE_wide_5km[-picked_CPUE_5km,]
df_CPUE_wide_train_5km =df_CPUE_wide_5km[picked_CPUE_5km,]

##Binary model
picked_binary_5km = sample(seq_len(nrow(df_binary_wide_5km)),size = sample_size_5km)
df_binary_wide_test_5km = df_binary_wide_5km[-picked_binary_5km,]
df_binary_wide_train_5km = df_binary_wide_5km[picked_binary_5km,]

##Poisson model
picked_5km = sample(seq_len(nrow(df_count_wide_5km)),size = sample_size_5km) 
df_count_wide_test_5km = df_count_wide_5km[-picked_5km,]
df_count_wide_train_5km = df_count_wide_5km[picked_5km,]

```

#### Load cross-validation functions

```{r}
library(gtools)

pastePerm<- function(row, names){
  keep<- which(row==1)
  if(length(keep)==0){
    return('1')
  }else{
    return(paste(names[keep],collapse='+'))
  }
}
my_sqrt <- function(var1){
  sqrt(var1) #take square root of variable 
} #construct model formulas 

dredgeform<- function(pred, covars, alwaysIn=''){ #always in is set to empty string
  p<- length(covars) #number of independent variables
  perm.tab<- permutations(2, p, v=c(0,1), repeats.allowed=T) #for different combinations of predictor variables
  myforms<- NULL #store formulas 
  for(j in 1:nrow(perm.tab)){
    myforms[j]<- pastePerm(perm.tab[j,], covars) #function above
  }
  myforms<- paste0(pred, '~',myforms) #predicted variable and formula
  return(myforms)
}

allformulas <- dredgeform(pred = "red_drum", covars = c("s(avg_depth, k= 10)", "s(avg_sdo, k= 10)", "s(SAVDist_km, k= 10)", "s(InletDist_km, k= 10)", "s(NoFishRest, k= 10)", "s(atlantic_menhaden, k= 10)", "s(atlantic_croaker, k= 10)", "s(southern_flounder, k= 10)", "s(spot, k= 10)", "factor(FishingAll_num)", "factor(Sedsize_common)"))
                                                        
# "avg_stemp", "avg_sdo", "SAVDist_km", "InletDist_km", "NoFishRest", "atlantic_menhaden", "atlantic_croaker", "southern_flounder", "spot", "FishingAll_num", "Sedsize_common"))
```

#### Formula selection

##### Tweedie cross-validation

```{r}
#10 km
compare_var_tw <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_tw) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {
model_tw <- gam(as.formula(allformulas[i]), family= tw(link= "log"), method= "REML", data=df_count_wide)
compare_var_tw[i, 1] <- allformulas[i]
compare_var_tw[i, 2] <- AIC(model_tw)
}

t <- compare_var_tw %>% arrange(AIC) 

t[1,1]

model_tw_picked <- gam(red_drum~ s(avg_depth, k=5) + s(avg_stemp, k= 5) + s(atlantic_menhaden, k=5) + s(SAVDist_km, k=5) + Sedsize_common, family= tw(link= "log"), method= "REML", data=df_count_wide_5km)
summary(model_tw_picked)

#5 km
compare_var_tw5 <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_tw5) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {
model_tw5 <- gam(as.formula(allformulas[i]), family= tw(link= "log"), method= "REML", data=df_count_wide_5km)
compare_var_tw5[i, 1] <- allformulas[i]
compare_var_tw5[i, 2] <- AIC(model_tw5)
}

compare_var_tw5 %>% arrange(AIC)

model_tw5_picked <- gam(red_drum~ s(avg_depth, k=5) + s(InletDist_km, k= 5) + s(atlantic_menhaden, k=5) + s(southern_flounder, k=5) + FishingAll_num, family= tw(link= "log"), method= "REML", data=df_count_wide_5km)
summary(model_tw5_picked)
```

##### Poisson GAM cross-validation

```{r}
#10 km
compare_var_pg <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_pg) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {
model_pg <- gam(as.formula(allformulas[i]), family= poisson(), method= "REML", data=df_count_wide)
compare_var_pg[i, 1] <- allformulas[i]
compare_var_pg[i, 2] <- AIC(model_pg)
}

sel <- compare_var_pg %>% arrange(AIC)
sel[1,1]

model_picked_10 <- gam(red_drum~ s(avg_depth, bs="ts", k=10) + s(avg_sdo, bs="ts", k=10) + s(SAVDist_km, bs="ts", k=10) + s(InletDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num), family= poisson(), method= "REML", data=df_count_wide)
summary(model_picked_10)
summary(model_pg_picked)
gam.check(model_picked_10)

model_pg_picked <- gam(red_drum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(SAVDist_km, bs="ts", k=5) + s(NoFishRest, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide)
summary(model_pg_picked)
gam.check(model_pg_picked)

?gam()
#	If this is TRUE then gam can add an extra penalty to each term so that it can be penalized to zero. This means that the smoothing parameter estimation that is part of fitting can completely remove terms from the model. If the corresponding smoothing parameter is estimated as zero then the extra penalty has no effect. Use gamma to increase level of penalization.

#5km
compare_var_pg5 <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var_pg5) <- c("formula", "AIC")

for (i in 1:length(allformulas)) {
model_pg5 <- gam(as.formula(allformulas[i]), family= poisson(), method= "REML", data=df_count_wide_5km)
compare_var_pg5[i, 1] <- allformulas[i]
compare_var_pg5[i, 2] <- AIC(model_pg5)
}

compare_var_pg5 %>% arrange(AIC)

red_drum~avg_depth+avg_stemp+avg_sdo+InletDist_km+atlantic_menhaden+atlantic_croaker+southern_flounder+spot+FishingAll_num+Sedsize_commo

model_pg5_picked <- gam(red_drum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide_5km)
summary(model_pg5_picked)
```

```{r}
set.seed(123)
compare_var <- as.data.frame(matrix(ncol = 2, nrow = 0))
colnames(compare_var) <- c("formula", "AIC")

for ( i in 1:length(allformulas)) {

model <- gam(as.formula(allformulas[i]), data = cities_df, family = "binomial"(link= logit))

# Summarize the results
compare_var[i, 1] <- allformulas[i]
compare_var[i, 2] <- AIC(model)
}

compare_var %>% arrange(AIC)
```

```{r}
set.seed(123)
library(caret)
compare_var <- as.data.frame(matrix(ncol = 4, nrow = 0))
colnames(compare_var) <- c("formula", "AUC", "sensitivity", "specificity")

for ( i in 2:length(allformulas)) {
  
train.control <- trainControl(method = "repeatedcv", number = 3, repeats = 10, 
                     summaryFunction=twoClassSummary, 
                     classProbs=T,
                     savePredictions = T)

# Train the full model
model <- train(as.formula(allformulas[i]), data = df_count_wide, method = "gam", family = "binomial", trControl = train.control, metric = "ROC")

# Summarize the results
compare_var[i, 1] <- allformulas[i]
compare_var[i, 2] <- model$results$ROC
compare_var[i, 3] <- model$results$Sens
compare_var[i, 4] <- model$results$Spec


}

compare_var %>% arrange(-AUC)
```

```{r}
model_pg5_picked <- gam(red_drum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide_5km)

tester <- gam(red_drum~ s(avg_depth, bs="ts", k=5) + s(avg_stemp, bs="ts", k=5) + s(avg_sdo, bs="ts", k=5) + s(InletDist_km, bs="ts", k=5) + s(atlantic_menhaden, bs="ts", k=5) + s(atlantic_croaker, bs="ts", k=5) + s(southern_flounder, bs="ts", k=5) + s(spot, bs="ts", k=5) + factor(FishingAll_num) + factor(Sedsize_common), family= poisson(), method= "REML", data=df_count_wide_5km, select= TRUE)

summary(model_pg5_picked)
summary(tester)

gam.check(model_pg5_picked)
gam.check(tester)
```

##### gJam:

```{r}
#Functions
pastePerm<- function(row, names){
  keep<- which(row==1)
  if(length(keep)==0){
    return('1')
  }else{
    return(paste(names[keep],collapse='+'))
  }
}
dredgeGJAM<- function(covars, alwaysIn=''){
  p<- length(covars)
  perm.tab<- permutations(2, p, v=c(0,1), repeats.allowed=T)
  myforms<- NULL
  for(j in 1:nrow(perm.tab)){
    myforms[j]<- pastePerm(perm.tab[j,], covars)
  }
  myforms<- paste0('~', alwaysIn,'+', myforms)
  return(myforms)
}
library(gtools)

r2_general <-function(preds,actual){ 
  return(1- sum((preds - actual) ^ 2)/sum((actual - mean(actual))^2))
}

RMSE_func <- function(preds, actual){
  return(sqrt(mean((actual - preds)^2)))
         }
```

```{r}
#Setup data
#Count dataset 
df_count <- read_csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_count_avg_edt.csv")  
df_count <- df_count %>% dplyr::select(-c(...1, CPUE, CPUE_stdzd, mean_CPUE, mean_CPUE_stdzd))
df_count$Speciescommonname <- gsub(" ", ".", df_count$Speciescommonname) #gJam doesn't like _ in column names

##Standardized catch per unit effort 
CPUE_grid_avg_edt <- read.csv("~/Documents/GitHub/NCBlueCrab_Predators/Data/CPUE/CPUE_grid_avg_edt.csv")
CPUE_grid_avg_edt <- CPUE_grid_avg_edt[,-1]
CPUE_grid_avg_edt <- CPUE_grid_avg_edt %>% mutate_at(c("Sedsize_common", "ShorelineType", "ITP", "Survey"), as.factor)
CPUE_grid_avg_edt$Speciescommonname <- gsub(" ", ".", CPUE_grid_avg_edt$Speciescommonname)

df_count_wide <- df_count %>% filter(Survey %in% "P915") %>% ungroup() %>% pivot_wider(names_from = "Speciescommonname", values_from = "avg_count") %>% drop_na()

xdata <- df_count_wide %>% dplyr::select(avg_depth, avg_stemp, avg_ssal, avg_sdo, SAVDist_km, InletDist_km, NoFishRest,  FishingAll_num, Sedsize_common) %>% mutate_at(vars(c(Sedsize_common, FishingAll_num)), as.factor)
colnames(xdata) <- gsub(pattern = "_", replacement = ".", colnames(xdata))

##ydata: species of interest, same dimensions as xdata 
ydata <- df_count_wide %>% dplyr::select(american.shad, atlantic.thread.herring:bonnethead.shark, bull.shark:cownose.ray, gizzard.shad:atlantic.sharpnose.shark, silver.perch:summer.flounder, -silversides)

##edata: effort, columns as number of species and values as effort values  
edata <- list(columns=1:ncol(ydata), values = 1)

tot <- cbind(xdata, ydata)
```

```{r}
#Tuning for gJam: Code from GFW_manuscript.Rmd, Sarah Roberts
smp_size <- floor(0.70 * nrow(tot))
set.seed(123)
train_ind <- sample(seq_len(nrow(tot)), size = smp_size)
train <- tot[train_ind, ]
test <- tot[-train_ind, ]

colnames(xdata)
xnames <- c("avg.depth", "avg.stemp", "avg.ssal", "avg.sdo", "SAVDist.km", "InletDist.km", "NoFishRest", "FishingAll.num",  "Sedsize.common")

xdata <- train[,xnames] #training xdata
xdata <- as.data.frame(xdata)
ydata <- train[,colnames(ydata)]
ml <- list(ng = 100, burnin = 40, typeNames = 'DA', effort= edata)

#find all possible interactions and variables
xdata2 <- train[,c("avg.depth", "avg.stemp", "avg.ssal", "avg.sdo", "SAVDist.km", "InletDist.km", "NoFishRest", "FishingAll.num",  "Sedsize.common")]
inter <- model.matrix( ~.^2, data=xdata2) #create interactions
covars <- colnames(inter)
covars <- covars[c(2, 6,7, 9,10,11,37)] #select covars you're interested in
covars <- c(covars)
allformulas<- dredgeGJAM(covars, alwaysIn='avg.stemp + avg.ssal + avg.sdo')
allformulas <- gsub(pattern = ":", replacement = "*", allformulas)

savestuff<- as.data.frame(matrix(NA, length(allformulas), 15))

colnames(savestuff) = c("Formula", "DIC", "R2", "RMSE", "Mean_obs", "R2fishing", "R2trawlers","R2pole","R2pots","R2gillnets", "RMSEfishing", "RMSEtrawlers","RMSEpole","RMSEpots","RMSEgillnets")
```

```{r}
#Run gJam
pb <- txtProgressBar(0, length(allformulas), style = 3)
### Out of Sample Prediction Part
test <- test[complete.cases(test),]

    xtest <- test[,xnames]
    xtest <- as.data.frame(xtest)
    ytest <- test[,colnames(ydata)]
    newdata <- list(xdata = xtest, nsim=500)
    
for(M in 1:length(allformulas)){
    tryCatch({
      form <- allformulas[[M]]
    model    <- gjam(form, xdata, ydata, modelList = ml)
    name <- form
    out_of_sample_prediction_non_conditional <- gjamPredict(model, newdata = newdata)
    y_pred <- out_of_sample_prediction_non_conditional$sdList$yMu
    y_obs <- ytest 
    y_pred_long <- as.data.frame(y_pred) %>% pivot_longer(cols = american.shad:summer.flounder, names_to = c("spec"))
    y_obs_long <- as.data.frame(y_obs) %>% pivot_longer(cols =american.shad:summer.flounder, names_to = c("spec"))
    
    tot <- cbind(y_pred_long$value, y_obs_long$value)
    colnames(tot) <- c("pred", "obs")
    tot <- as.data.frame(tot)
colnames(ydata)
    ###
    if(inherits(model, 'try-error'))next
    savestuff[M,1]<- allformulas[[M]]
    savestuff[M,2]<- model$fit$DIC
    savestuff[M,3] <- r2_general(tot$pred, tot$obs)
    savestuff[M,4] <- RMSE_func(actual = tot$obs, pred = tot$pred) 
    savestuff[M,5] <- mean(tot$obs)
    savestuff[M,6] <- r2_general(y_pred[,40], y_obs[,40])
    savestuff[M,7] <- r2_general(y_pred[,41], y_obs[,41])
    savestuff[M,8] <- r2_general(y_pred[,42], y_obs[,42])
    savestuff[M,9] <- r2_general(y_pred[,43], y_obs[,43])
    savestuff[M,10] <- RMSE_func(actual = y_obs[,40], pred = y_pred[,40]) 
    savestuff[M,11] <- RMSE_func(actual = y_obs[,41], pred = y_pred[,41]) 
    savestuff[M,12] <- RMSE_func(actual = y_obs[,42], pred = y_pred[,42]) 
    savestuff[M,13] <- RMSE_func(actual = y_obs[,43], pred = y_pred[,43]) 
    setTxtProgressBar(pb, M)
    Sys.sleep(time = 1)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

write.csv(savestuff, "~/Desktop/modelruns.csv")


#Lowest RMSPE 
```
